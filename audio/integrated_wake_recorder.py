import sys
import time
import signal
import threading
import socket
import json
import requests
import numpy as np
import tempfile
import os
import uuid
from collections import deque

from audio_record import AudioRecorder, CHANNELS, SAMPLE_WIDTH, FRAME_RATE
from wake_word_detector import WakeWordDetector 

# é…ç½®
TTS_SERVER_URL = "http://192.168.77.103:28001/speak_msg"
TTS_MONITOR_URL = "http://192.168.77.103:28001/monitor"
ASR_SERVER_URL = "http://localhost:8003/asr"
AGENT_SERVER_URL = "http://192.168.77.102:8602/v1/chat/completions"
WAKE_WORD = "å°å®‰"

class TTSClient:
    """HTTP TTS å®¢æˆ·ç«¯ - æµå¼æ’­æ”¾ + ç­‰å¾…å®Œæˆ"""
    
    @staticmethod
    def speak(text, volume=80, wait=True, source="integrated"):
        """å‘é€TTSè¯·æ±‚å¹¶å¯é€‰ç­‰å¾…æ’­æ”¾å®Œæˆ"""
        if not text:
            return
        
        try:
            payload = {
                "speak_msg": text,
                "volume": volume,
                "source": source
            }
            headers = {"Content-Type": "application/json"}
            
            print(f"ğŸ”Š {text}")
            response = requests.post(TTS_SERVER_URL, json=payload, headers=headers, timeout=2.0)
            
            if response.status_code != 200:
                print(f"âš ï¸ TTSé”™è¯¯: {response.status_code}")
                return
            
            result = response.json()
            
            if result.get('msg') == 'ignored_filtered':
                print(f"âš ï¸ TTSè¢«è¿‡æ»¤")
                return
            
            data = result.get('data')
            if not data or not isinstance(data, dict):
                print(f"âš ï¸ TTSå“åº”å¼‚å¸¸")
                return
            
            task_id = data.get('task_id')
            
            if wait and task_id:
                TTSClient._wait_for_completion(task_id)
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ TTSè¯·æ±‚å¤±è´¥: {e}")
        except Exception as e:
            print(f"âŒ TTSå¤±è´¥: {e}")

    @staticmethod
    def _wait_for_completion(task_id, timeout=30):
        """è½®è¯¢ç›‘æ§æ¥å£ï¼Œç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆç»ˆæä¼˜åŒ–ç‰ˆï¼‰"""
        start_time = time.time()
        check_interval = 0.05  # ğŸ”‘ ç¼©çŸ­è½®è¯¢é—´éš”åˆ° 50ms
        
        task_started = False
        consecutive_empty_checks = 0  # ğŸ”‘ è¿ç»­ç©ºé—²æ£€æŸ¥æ¬¡æ•°
        
        while time.time() - start_time < timeout:
            try:
                response = requests.get(TTS_MONITOR_URL, timeout=2.0)
                
                if response.status_code == 200:
                    data = response.json()
                    active_task = data.get('active_task')
                    queue_length = data.get('queue_length', 0)
                    
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£åœ¨æ’­æ”¾
                    if active_task:
                        current_id = active_task.get('id')
                        if current_id == task_id:
                            task_started = True
                            consecutive_empty_checks = 0  # é‡ç½®è®¡æ•°å™¨
                            time.sleep(check_interval)
                            continue
                    
                    # ğŸ”‘ ä¿®å¤: ä»»åŠ¡å¼€å§‹åï¼Œéœ€è¦è¿ç»­3æ¬¡æ£€æŸ¥éƒ½ä¸ºç©ºæ‰è®¤ä¸ºå®Œæˆ
                    if task_started:
                        if not active_task and queue_length == 0:
                            consecutive_empty_checks += 1
                            
                            # ğŸ”‘ å…³é”®: è¿ç»­3æ¬¡ç©ºé—²æ£€æŸ¥æ‰è¿”å›
                            if consecutive_empty_checks >= 3:
                                # ğŸ”‘ é¢å¤–å»¶è¿Ÿç¡®ä¿éŸ³é¢‘å®Œå…¨æ’­æ”¾å®Œæ¯•
                                time.sleep(0.2)
                                return True
                        else:
                            consecutive_empty_checks = 0
                    
            except:
                pass
                
            time.sleep(check_interval)
        
        return False

class ASRClient:
    """HTTP ASR å®¢æˆ·ç«¯"""
    
    @staticmethod
    def recognize(audio_data, use_itn=False, verbose=False):
        """
        è°ƒç”¨è¿œç¨‹ ASR æœåŠ¡è¯†åˆ«éŸ³é¢‘
        :param verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        if audio_data is None or len(audio_data) == 0:
            return ""
        
        try:
            # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º WAV ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_path = tmp_file.name
                
                import wave
                with wave.open(tmp_path, 'wb') as wav_file:
                    wav_file.setnchannels(CHANNELS)
                    wav_file.setsampwidth(SAMPLE_WIDTH)
                    wav_file.setframerate(FRAME_RATE)
                    wav_file.writeframes(audio_data.tobytes())
            
            # ä¸Šä¼ åˆ° ASR æœåŠ¡
            with open(tmp_path, 'rb') as f:
                files = {'file': (f'audio_{int(time.time())}.wav', f, 'audio/wav')}
                response = requests.post(ASR_SERVER_URL, files=files, timeout=10.0)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(tmp_path)
            except:
                pass
            
            # è§£æç»“æœ
            if response.status_code == 200:
                result = response.json()
                text = result.get('text', '').strip()
                return text
            else:
                return ""
                
        except Exception as e:
            if verbose:
                print(f"âŒ ASRå¤±è´¥: {e}")
            return ""

class AgentClient:
    """å¤§æ¨¡å‹å¯¹è¯ Agent å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.api_url = AGENT_SERVER_URL
        self.session_id = str(uuid.uuid4())
        self.memory_data = None # è®°å¿†æ•°æ®ï¼Œåˆå§‹ä¸ºç©º
        
    def chat(self, query):
        """å‘é€å¯¹è¯è¯·æ±‚"""
        if not query:
            return "è¯·å†è¯´ä¸€æ¬¡"
            
        payload = {
            "session_id": self.session_id,
            "request_id": str(uuid.uuid4()),
            "query": query,
            "memory_data": self.memory_data
        }
        
        try:
            print(f"ğŸ¤– è¯·æ±‚Agent: {query}")
            response = requests.post(self.api_url, json=payload, timeout=15.0)
            
            if response.status_code == 200:
                data = response.json()
                
                # æå–å›å¤
                reply_text = data.get("response", "")
                if not reply_text:
                    return "Agentå›å¤ä¸ºç©º"
                    
                # æ›´æ–°çŠ¶æ€ï¼ˆsession_id å’Œ memoryï¼‰
                if "session_id" in data:
                    self.session_id = data["session_id"]
                if "memory" in data:
                    self.memory_data = data["memory"]
                    
                return reply_text
            else:
                print(f"âŒ Agent APIé”™è¯¯: {response.status_code}")
                return "å¤§è„‘è¿æ¥å‡ºé”™äº†"
                
        except requests.exceptions.Timeout:
            print("âŒ Agentè¯·æ±‚è¶…æ—¶")
            return "æ€è€ƒè¶…æ—¶äº†"
        except Exception as e:
            print(f"âŒ Agentè¯·æ±‚å¤±è´¥: {e}")
            return "ç½‘ç»œå¼€å°å·®äº†"

class RobotInteractionSystem(AudioRecorder):
    """ç²¾ç®€ç‰ˆäººæœºäº¤äº’ç³»ç»Ÿ - ä½¿ç”¨è¿œç¨‹ ASR"""
    
    def __init__(self, interface_name="eth0"):
        super().__init__(interface_name)
        
        print("ğŸš€ åˆå§‹åŒ–äº¤äº’ç³»ç»Ÿ...")
        
        # æµ‹è¯• ASR æœåŠ¡è¿é€šæ€§ï¼ˆé™é»˜ï¼‰
        try:
            response = requests.get(ASR_SERVER_URL.replace('/asr', '/'), timeout=3.0)
            if response.status_code == 200:
                print(f"âœ… ASRæœåŠ¡è¿æ¥æˆåŠŸ")
        except:
            print(f"âš ï¸ ASRæœåŠ¡è¿æ¥å¤±è´¥")

        # ğŸ”‘ é™é»˜åˆå§‹åŒ–å”¤é†’æ£€æµ‹å™¨
        self.wake_detector = WakeWordDetector(
            target_wake_word=WAKE_WORD, 
            confidence_threshold=0.6,
            verbose=False  # å…³é”®ï¼šä¸è¾“å‡ºåˆå§‹åŒ–æ—¥å¿—
        )
        
        # åˆå§‹åŒ– Agent å®¢æˆ·ç«¯
        self.agent_client = AgentClient()
        
        # çŠ¶æ€æ§åˆ¶
        self.is_running = True
        self.audio_running = True
        self.is_speaking = False  # ğŸ¤– æœºå™¨äººæ˜¯å¦æ­£åœ¨è¯´è¯
        self.mode = "WAKE_DETECTION"
        
        # éŸ³é¢‘ç¼“å†²
        self.wake_buffer = deque(maxlen=int(3.0 * FRAME_RATE))
        self.user_speech_buffer = []
        self.user_speech_start_time = 0
        self.user_speech_timeout = 5.0
        
        # ğŸ”‘ å…³é”®ä¿®æ”¹ï¼šå…ˆè®¾ç½® socketï¼Œå†å¯åŠ¨çº¿ç¨‹
        self.setup_audio_receiver()
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.process_thread = threading.Thread(target=self._audio_processing_loop, daemon=True)
        self.process_thread.start()
        
        # å¯åŠ¨éŸ³é¢‘æ¥æ”¶çº¿ç¨‹
        self.audio_thread = threading.Thread(target=self._audio_receiver_loop, daemon=True)
        self.audio_thread.start()

        # â³ å¯åŠ¨å€’è®¡æ—¶ï¼Œè®©ç”¨æˆ·æ˜ç¡®çŸ¥é“ä½•æ—¶å¯ä»¥è¯´è¯
        print("\nâ³ ç³»ç»Ÿå‡†å¤‡ä¸­...")
        for i in range(3, 0, -1):
            print(f"   {i}...", end="\r")
            time.sleep(0.5)
        print("   ğŸš€ è¯·è¯´è¯!   \n")

    def _audio_receiver_loop(self):
        """éŸ³é¢‘æ¥æ”¶çº¿ç¨‹ï¼ˆé™é»˜ï¼‰"""
        while self.audio_running:
            try:
                data, addr = self.socket.recvfrom(2048)
                self.process_audio_frame(data)
            except socket.timeout:
                continue
            except Exception as e:
                if self.audio_running:
                    print(f"âŒ éŸ³é¢‘æ¥æ”¶é”™è¯¯: {e}")
                break

    def process_audio_frame(self, audio_data):
        """æ¥æ”¶UDPéŸ³é¢‘æ•°æ®ï¼ˆé™é»˜ï¼‰"""
        # ğŸ¤– å¦‚æœæœºå™¨äººæ­£åœ¨è¯´è¯ï¼Œä¸¢å¼ƒéº¦å…‹é£æ•°æ®ï¼ˆé˜²æ­¢å¬åˆ°è‡ªå·±ï¼‰
        if self.is_speaking:
            return

        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            
            if self.mode == "WAKE_DETECTION":
                self.wake_buffer.extend(audio_np)
            elif self.mode == "USER_RECORDING":
                self.user_speech_buffer.extend(audio_np)
                
        except:
            pass

    def speak(self, text):
        """å°è£…çš„è¯´è¯æ–¹æ³•ï¼Œè¯´è¯æœŸé—´æš‚åœå½•éŸ³"""
        if not text:
            return
            
        self.is_speaking = True
        try:
            # æ¸…ç©ºç¼“å†²åŒºï¼Œé˜²æ­¢ä¹‹å‰çš„æ®‹ç•™
            self.wake_buffer.clear()
            # self.user_speech_buffer = [] # list æ²¡æœ‰ clear? Python3 åº”è¯¥æœ‰ï¼Œæˆ–è€…é‡æ–°èµ‹å€¼
            self.user_speech_buffer.clear()
            
            TTSClient.speak(text, wait=True)
        finally:
            self.is_speaking = False
            # è¯´è¯ç»“æŸåå†æ¬¡æ¸…ç©ºï¼Œç¡®ä¿å¹²å‡€
            self.wake_buffer.clear()
            self.user_speech_buffer.clear()

    def _audio_processing_loop(self):
        """ä¸»å¤„ç†å¾ªç¯"""
        print(f"ğŸ‘‚ ç›‘å¬å”¤é†’è¯: {WAKE_WORD}\n")
        
        while self.is_running:
            if self.mode == "WAKE_DETECTION":
                self._do_wake_detection()
                # ğŸ”‘ å¢åŠ é—´éš”åˆ° 0.3sï¼Œé¿å…æ£€æµ‹å¤ªé¢‘ç¹æŠŠä¸€å¥è¯åˆ‡ç¢
                time.sleep(0.3)
                
            elif self.mode == "USER_RECORDING":
                self._check_recording_timeout()
                time.sleep(0.05)
            
    def _do_wake_detection(self):
        """æ‰§è¡Œå”¤é†’æ£€æµ‹"""
        # ç¼“å†²åŒºæ•°æ®ä¸è¶³æ—¶ä¸æ£€æµ‹ (ä»0.2ç§’æ¢å¤åˆ°0.5ç§’ï¼Œä¿è¯æœ‰è¶³å¤Ÿæ•°æ®)
        if len(self.wake_buffer) < int(0.5 * FRAME_RATE):
            return

        # ğŸ”‘ ä¼˜åŒ–ï¼šè®¡ç®—æœ€è¿‘ 1.0 ç§’çš„èƒ½é‡ (ä»0.5så¢åŠ åˆ°1.0s)
        # æ—¢èƒ½é¿å…é•¿é™éŸ³ç¨€é‡Šï¼Œåˆèƒ½åŒ…å«å®Œæ•´è¯è¯­
        check_len = int(1.0 * FRAME_RATE)
        curr_audio = np.array(list(self.wake_buffer))
        
        if len(curr_audio) > check_len:
            recent_audio = curr_audio[-check_len:]
        else:
            recent_audio = curr_audio
            
        energy = np.sqrt(np.mean(recent_audio.astype(np.float32) ** 2))
        
        # è°ƒè¯•ï¼šå§‹ç»ˆæ‰“å°èƒ½é‡å€¼
        if energy > 10:
            print(f"\rğŸ”Š èƒ½é‡: {energy:.1f}   ", end="", flush=True)
        
        # é˜ˆå€¼ä¿æŒ 200
        if energy < 200:
            return
            
        print(f"\nâš¡ èƒ½é‡è§¦å‘ ({energy:.1f})ï¼Œæ­£åœ¨è¯·æ±‚ASRè¯†åˆ«...")

        # ASR è¯†åˆ« (å‘é€æœ€è¿‘ 1.5 ç§’çš„æ•°æ®ï¼Œç¡®ä¿åŒ…å«å®Œæ•´å”¤é†’è¯)
        # å³ä½¿èƒ½é‡åªè®¡ç®—äº†1ç§’ï¼Œè¯†åˆ«æ—¶å¤šå‘ä¸€ç‚¹æ•°æ®æ›´ä¿é™©
        recognize_len = int(1.5 * FRAME_RATE)
        if len(curr_audio) > recognize_len:
            audio_to_recognize = curr_audio[-recognize_len:]
        else:
            audio_to_recognize = curr_audio

        # ASR è¯†åˆ« (å¼€å¯è¯¦ç»†æ¨¡å¼ä»¥ä¾¿è°ƒè¯•é”™è¯¯)
        text = ASRClient.recognize(audio_to_recognize, use_itn=False, verbose=True)
        
        if not text:
            # å¦‚æœæ˜¯é«˜èƒ½é‡ä½†è¯†åˆ«ä¸ºç©ºï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æ— æ³•è¯†åˆ«
            # print("âš ï¸ ASRè¿”å›ä¸ºç©º")
            return
            
        print(f"ğŸ‘‚ ASRè¯†åˆ«ç»“æœ: [{text}]")
        if not text:
            return

        # æ¨¡ç³ŠåŒ¹é…å”¤é†’è¯
        is_wake, conf, match = self.wake_detector.detect_wake_word(text)
        
        # ğŸ”‘ åªæœ‰å”¤é†’æˆåŠŸæ—¶æ‰è¾“å‡ºæ—¥å¿—
        if is_wake:
            print(f"âœ¨ å”¤é†’æˆåŠŸ! (åŒ¹é…: {match}, ç½®ä¿¡åº¦: {conf:.2f})")
            
            # æ’­æ”¾å›åº”å¹¶ç­‰å¾…å®Œæˆ (ä½¿ç”¨å°è£…çš„ speak æ–¹æ³•)
            self.speak("æˆ‘åœ¨ï¼Œè¯·å©å’ã€‚")
            
            # TTS æ’­æ”¾å®Œæˆåæ‰åˆ‡æ¢çŠ¶æ€
            self._switch_to_recording()

    def _switch_to_recording(self):
        """åˆ‡æ¢åˆ°ç”¨æˆ·æŒ‡ä»¤å½•åˆ¶æ¨¡å¼"""
        self.mode = "USER_RECORDING"
        self.user_speech_buffer = []
        self.user_speech_start_time = time.time()
        print(f"ğŸ¤ å½•åˆ¶ä¸­... (æœ€å¤§ {self.user_speech_timeout}ç§’)\n")

    def _check_recording_timeout(self):
        """æ£€æŸ¥å½•éŸ³æ˜¯å¦è¶…æ—¶æˆ–ç»“æŸ"""
        elapsed = time.time() - self.user_speech_start_time
        
        if elapsed > self.user_speech_timeout:
            print("â¹ï¸ å½•éŸ³ç»“æŸï¼Œå¼€å§‹å¤„ç†...\n")
            print("ğŸš« ç³»ç»Ÿå¿™ï¼šæ­£åœ¨æ€è€ƒå’Œå›ç­” (æ­¤æ—¶æ— æ³•å”¤é†’)")
            self._process_user_intent()
            
            # å¤„ç†å®Œååˆ‡å›å”¤é†’æ¨¡å¼
            self.mode = "WAKE_DETECTION"
            self.wake_detector.reset_cooldown()
            
            # ğŸ”‘ å…³é”®ä¼˜åŒ–ï¼šåˆ‡å›å”¤é†’æ¨¡å¼æ—¶ï¼Œä¸å®Œå…¨æ¸…ç©ºç¼“å†²åŒº
            # è€Œæ˜¯ä¿ç•™æœ€å 1.0 ç§’çš„éŸ³é¢‘ï¼Œé˜²æ­¢ç”¨æˆ·æŠ¢è¯å¯¼è‡´çš„æ¼æ£€
            keep_samples = int(1.0 * FRAME_RATE)
            if len(self.user_speech_buffer) > keep_samples:
                # ä»ç”¨æˆ·å½•éŸ³ç¼“å†²çš„æœ«å°¾æå–æ•°æ®å¡«å…¥å”¤é†’ç¼“å†²
                recent_audio = self.user_speech_buffer[-keep_samples:]
                self.wake_buffer.extend(recent_audio)
            else:
                self.wake_buffer.clear()
                
            print(f"ğŸ‘‚ ç›‘å¬æ¢å¤: {WAKE_WORD}\n")

    def _process_user_intent(self):
        """å¤„ç†ç”¨æˆ·æŒ‡ä»¤"""
        if not self.user_speech_buffer:
            return

        audio_data = np.array(self.user_speech_buffer)
        
        # è¯†åˆ«ç”¨æˆ·è¯´çš„è¯ï¼ˆè¯¦ç»†æ¨¡å¼ï¼‰
        text = ASRClient.recognize(audio_data, use_itn=True, verbose=True)
        
        if text:
            print(f"ğŸ“ è¯†åˆ«: {text}")
            # ç®€å•çš„ç¡®è®¤ï¼ˆå¯é€‰ï¼Œå¦‚æœAgentå“åº”å¿«å¯ä»¥å»æ‰ï¼Œæˆ–è€…ä¿ç•™ä½œä¸ºå¡«è¡¥ç©ºç™½ï¼‰
            # TTSClient.speak(f"æ”¶åˆ°,æ‚¨è¯´çš„æ˜¯:{text}", wait=True)
            
            # è°ƒç”¨ Agent è·å–å›å¤
            print("ğŸ¤” æ€è€ƒä¸­...")
            agent_response = self.agent_client.chat(text)
            print(f"ğŸ¤– å›å¤: {agent_response}")
            
            # æ’­æ”¾ Agent å›å¤
            self.speak(agent_response)
            
        else:
            print(f"ğŸ“ è¯†åˆ«: (ç©º)")
            self.speak("æŠ±æ­‰,æˆ‘æ²¡å¬æ¸…ã€‚")
        
        print()  # ç©ºè¡Œåˆ†éš”

    def cleanup(self):
        """èµ„æºæ¸…ç†"""
        self.is_running = False
        self.audio_running = False
        
        if hasattr(self, 'process_thread') and self.process_thread.is_alive():
            self.process_thread.join(timeout=2)
        if hasattr(self, 'audio_thread') and self.audio_thread.is_alive():
            self.audio_thread.join(timeout=2)
            
        super().cleanup()

def main():
    def signal_handler(sig, frame):
        print("\nğŸ›‘ é€€å‡º")
        if 'system' in locals():
            system.cleanup()
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)

    if len(sys.argv) < 2:
        interface = "eth0"
    else:
        interface = sys.argv[1]

    system = RobotInteractionSystem(interface)
    
    try:
        # ğŸ”‘ å…³é”®ä¿®æ”¹ï¼šç§»é™¤è¿™é‡Œçš„ setup_audio_receiver() è°ƒç”¨
        # system.setup_audio_receiver()  # å·²åœ¨ __init__ ä¸­è°ƒç”¨
        
        print("ğŸ¯ ç³»ç»Ÿè¿è¡Œä¸­ (Ctrl+C é€€å‡º)\n")
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\næ¥æ”¶åˆ°é€€å‡ºä¿¡å·")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
    finally:
        system.cleanup()

if __name__ == "__main__":
    main()
