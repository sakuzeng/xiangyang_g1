#!/usr/bin/env python3
"""
screen_detection_data_collector.py
================================

å±å¹•åˆ†å‰²æ•°æ®é‡‡é›†å™¨ - YOLO Segmentation æ ¼å¼

åŠŸèƒ½ï¼š
1. ä½¿ç”¨ RealSense æ‘„åƒå¤´é‡‡é›†å±å¹•å›¾åƒ
2. äº¤äº’å¼æ ‡æ³¨å±å¹•å››è§’ç‚¹
3. ä¿å­˜ YOLO åˆ†å‰²æ ¼å¼æ ‡æ³¨ (å½’ä¸€åŒ–å¤šè¾¹å½¢åæ ‡)
4. æ‰€æœ‰æ•°æ®ç»Ÿä¸€ä¿å­˜,åç»­é€šè¿‡ä¸“é—¨è„šæœ¬åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†

æ ‡æ³¨æ ¼å¼:
0 x1 y1 x2 y2 x3 y3 x4 y4
(class_id + 4ä¸ªè§’ç‚¹çš„å½’ä¸€åŒ–åæ ‡)

ä½¿ç”¨æ–¹æ³•:
python screen_detection_data_collector.py --resolution 960x540 --output-dir my_dataset/seg_960x540
"""

import os
import sys
from pathlib import Path
from typing import List, Tuple

import cv2
import numpy as np

# å¯¼å…¥å°è£…å¥½çš„ RealSense æ‘„åƒå¤´ç±»
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'loco', 'unitree_sdk_python'))
from unitree_sdk2py.camera.realsense_camera_client import RealSenseCamera


# æ”¯æŒçš„åˆ†è¾¨ç‡é…ç½®
SUPPORTED_RESOLUTIONS = {
    "1920x1080": (1920, 1080),
    "1280x720": (1280, 720),
    "960x540": (960, 540),
    "848x480": (848, 480),
    "640x480": (640, 480),
}


class ScreenSegmentationCollector:
    """å±å¹•åˆ†å‰²æ•°æ®é‡‡é›†å™¨ - YOLO Segmentation æ ¼å¼"""
    
    def __init__(self, output_dir: str, width: int = 960, height: int = 540):
        """
        åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨
        
        Args:
            output_dir: æ•°æ®é›†æ ¹ç›®å½•
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
        """
        self.width = width
        self.height = height
        self.output_dir = Path(output_dir)
        
        # åˆ›å»ºç®€å•çš„äºŒçº§ç›®å½•ç»“æ„
        self.images_dir = self.output_dir / "images"
        self.labels_dir = self.output_dir / "labels"
        self.images_dir.mkdir(parents=True, exist_ok=True)
        self.labels_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»º dataset.yaml (å¦‚æœä¸å­˜åœ¨)
        self._create_dataset_yaml()
        
        # æ ‡æ³¨çŠ¶æ€
        self.current_color_image = None
        self.screen_corners = []  # å±å¹•å››è§’ç‚¹ (åƒç´ åæ ‡)
        self.is_annotating = False
        self.sample_count = 0
        
        # æ˜¾ç¤ºå‚æ•°
        self.display_scale = self._get_display_scale()
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.camera = RealSenseCamera(width=width, height=height, fps=30)
        
        print(f"âœ… æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   åˆ†è¾¨ç‡: {width}x{height}")
        print(f"   æ•°æ®é›†ç›®å½•: {self.output_dir}")
    
    def _create_dataset_yaml(self):
        """åˆ›å»º YOLO æ•°æ®é›†é…ç½®æ–‡ä»¶"""
        yaml_path = self.output_dir / "dataset.yaml"
        if not yaml_path.exists():
            yaml_content = f"""# YOLO11 Segmentation Dataset Configuration
# ä½¿ç”¨å‰è¯·å…ˆè¿è¡Œæ•°æ®é›†åˆ’åˆ†è„šæœ¬å°† images/ å’Œ labels/ åˆ†ä¸º train/val/test

path: {self.output_dir.absolute()}
train: images/train
val: images/val
test: images/test

nc: 1  # number of classes
names: ['screen']  # class names
"""
            with open(yaml_path, 'w', encoding='utf-8') as f:
                f.write(yaml_content)
            print(f"âœ… å·²åˆ›å»º dataset.yaml")
    
    def _get_display_scale(self) -> float:
        """æ ¹æ®åˆ†è¾¨ç‡è‡ªåŠ¨è®¡ç®—æ˜¾ç¤ºç¼©æ”¾æ¯”ä¾‹"""
        max_display_width = 1200
        max_display_height = 900
        scale_x = max_display_width / self.width
        scale_y = max_display_height / self.height
        return min(scale_x, scale_y, 1.0)
    
    def mouse_callback(self, event, x, y, flags, param):
        """é¼ æ ‡å›è°ƒå‡½æ•° - æ ‡æ³¨å±å¹•å››è§’ç‚¹"""
        if not self.is_annotating or self.current_color_image is None:
            return
        
        if event == cv2.EVENT_LBUTTONDOWN and len(self.screen_corners) < 4:
            # è½¬æ¢å›åŸå§‹å›¾åƒåæ ‡
            orig_x = int(x / self.display_scale)
            orig_y = int(y / self.display_scale)
            
            self.screen_corners.append((orig_x, orig_y))
            print(f"âœ“ æ ‡æ³¨è§’ç‚¹ {len(self.screen_corners)}/4: ({orig_x}, {orig_y})")
            
            if len(self.screen_corners) == 4:
                # è®¡ç®—å½’ä¸€åŒ–åæ ‡
                sorted_corners = self._sort_corners(self.screen_corners)
                norm_coords = self._normalize_corners(sorted_corners)
                print(f"âœ“ å½’ä¸€åŒ–åæ ‡: {' '.join([f'{c:.6f}' for c in norm_coords])}")
                print("ğŸ“ æŒ‰ S ä¿å­˜ | æŒ‰ R é‡æ–°æ ‡æ³¨")
    
    def _normalize_corners(self, corners: List[Tuple[int, int]]) -> List[float]:
        """å°†åƒç´ åæ ‡å½’ä¸€åŒ–åˆ° [0, 1]"""
        normalized = []
        for x, y in corners:
            normalized.extend([x / self.width, y / self.height])
        return normalized
    
    def _sort_corners(self, corners: List[Tuple[int, int]]) -> List[Tuple[int, int]]:
        """æŒ‰å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹é¡ºåºæ’åˆ—è§’ç‚¹"""
        cx = sum(p[0] for p in corners) / 4
        cy = sum(p[1] for p in corners) / 4
        
        # æ ¹æ®è±¡é™åˆ†ç±»
        sorted_corners = []
        # å·¦ä¸Š
        sorted_corners.append(min([p for p in corners if p[0] < cx and p[1] < cy], 
                                 key=lambda p: (p[0]-cx)**2 + (p[1]-cy)**2, 
                                 default=min(corners, key=lambda p: p[0] + p[1])))
        # å³ä¸Š
        sorted_corners.append(min([p for p in corners if p[0] > cx and p[1] < cy], 
                                 key=lambda p: (p[0]-cx)**2 + (p[1]-cy)**2, 
                                 default=max(corners, key=lambda p: p[0] - p[1])))
        # å³ä¸‹
        sorted_corners.append(min([p for p in corners if p[0] > cx and p[1] > cy], 
                                 key=lambda p: (p[0]-cx)**2 + (p[1]-cy)**2, 
                                 default=max(corners, key=lambda p: p[0] + p[1])))
        # å·¦ä¸‹
        sorted_corners.append(min([p for p in corners if p[0] < cx and p[1] > cy], 
                                 key=lambda p: (p[0]-cx)**2 + (p[1]-cy)**2, 
                                 default=min(corners, key=lambda p: p[1] - p[0])))
        
        return sorted_corners
    
    def _draw_annotations(self, image: np.ndarray) -> np.ndarray:
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ ‡æ³¨ä¿¡æ¯"""
        display_img = image.copy()
        
        # ç¼©æ”¾æ˜¾ç¤º
        h, w = display_img.shape[:2]
        display_h = int(h * self.display_scale)
        display_w = int(w * self.display_scale)
        display_img = cv2.resize(display_img, (display_w, display_h))
        
        # ç»˜åˆ¶å·²æ ‡æ³¨çš„è§’ç‚¹
        for i, corner in enumerate(self.screen_corners):
            pt = (int(corner[0] * self.display_scale), int(corner[1] * self.display_scale))
            cv2.circle(display_img, pt, 5, (0, 255, 0), -1)
            cv2.putText(display_img, str(i+1), (pt[0]+10, pt[1]-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # ç»˜åˆ¶å¤šè¾¹å½¢è¿çº¿
        if len(self.screen_corners) >= 2:
            scaled_corners = [(int(x * self.display_scale), int(y * self.display_scale)) 
                            for x, y in self.screen_corners]
            for i in range(len(scaled_corners)):
                pt1 = scaled_corners[i]
                pt2 = scaled_corners[(i+1) % len(scaled_corners)]
                cv2.line(display_img, pt1, pt2, (255, 0, 0), 2)
        
        # å¡«å……å¤šè¾¹å½¢ (åŠé€æ˜)
        if len(self.screen_corners) == 4:
            overlay = display_img.copy()
            scaled_corners = np.array([(int(x * self.display_scale), int(y * self.display_scale)) 
                                     for x, y in self.screen_corners], dtype=np.int32)
            cv2.fillPoly(overlay, [scaled_corners], (0, 255, 255))
            cv2.addWeighted(overlay, 0.2, display_img, 0.8, 0, display_img)
        
        # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        font_scale = 0.6
        status_y = 30
        cv2.putText(display_img, f"åˆ†è¾¨ç‡: {self.width}x{self.height}", 
                   (10, status_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 2)
        
        status_y += 30
        if self.is_annotating:
            status = f"æ ‡æ³¨æ¨¡å¼ - å·²æ ‡æ³¨ {len(self.screen_corners)}/4 ä¸ªè§’ç‚¹"
            if len(self.screen_corners) == 4:
                status += " [æŒ‰ S ä¿å­˜]"
        else:
            status = "æŒ‰ A å¼€å§‹æ ‡æ³¨"
        cv2.putText(display_img, status, (10, status_y),
                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 2)
        
        status_y += 30
        cv2.putText(display_img, f"å·²é‡‡é›†: {self.sample_count} ä¸ªæ ·æœ¬", 
                   (10, status_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 2)
        
        return display_img
    
    def save_sample(self):
        """ä¿å­˜å½“å‰æ ‡æ³¨æ ·æœ¬"""
        if len(self.screen_corners) != 4:
            print("âŒ é”™è¯¯: éœ€è¦æ ‡æ³¨4ä¸ªè§’ç‚¹æ‰èƒ½ä¿å­˜")
            return
        
        if self.current_color_image is None:
            print("âŒ é”™è¯¯: æ— å›¾åƒæ•°æ®")
            return
        
        # æ’åºè§’ç‚¹ (å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹)
        sorted_corners = self._sort_corners(self.screen_corners)
        
        # ç”Ÿæˆæ–‡ä»¶å (4ä½ç¼–å·)
        sample_id = f"{self.sample_count:04d}"
        
        # ä¿å­˜å›¾åƒ
        image_path = self.images_dir / f"{sample_id}.png"
        cv2.imwrite(str(image_path), self.current_color_image)
        
        # ä¿å­˜ YOLO åˆ†å‰²æ ‡æ³¨
        label_path = self.labels_dir / f"{sample_id}.txt"
        norm_coords = self._normalize_corners(sorted_corners)
        
        with open(label_path, 'w', encoding='utf-8') as f:
            # æ ¼å¼: class_id x1 y1 x2 y2 x3 y3 x4 y4
            line = "0 " + " ".join([f"{c:.6f}" for c in norm_coords])
            f.write(line + "\n")
        
        print(f"\nâœ… æ ·æœ¬å·²ä¿å­˜: {sample_id}")
        print(f"   å›¾åƒ: {image_path.name}")
        print(f"   æ ‡æ³¨: {label_path.name}")
        print(f"   å†…å®¹: {line}\n")
        
        # æ›´æ–°è®¡æ•°å¹¶é‡ç½®
        self.sample_count += 1
        self.screen_corners = []
        self.is_annotating = False
    
    def run(self):
        """è¿è¡Œæ•°æ®é‡‡é›†ä¸»å¾ªç¯"""
        print(f"\nğŸš€ å¯åŠ¨å±å¹•åˆ†å‰²æ•°æ®é‡‡é›†å™¨")
        print("\næ“ä½œè¯´æ˜:")
        print("  A - å¼€å§‹æ ‡æ³¨æ¨¡å¼ (æŒ‰é¡ºåºç‚¹å‡»å±å¹•å››ä¸ªè§’ç‚¹)")
        print("  S - ä¿å­˜å½“å‰æ ‡æ³¨")
        print("  R - é‡ç½®å½“å‰æ ‡æ³¨")
        print("  Q/ESC - é€€å‡º")
        print("=" * 60)
        
        # å¯åŠ¨æ‘„åƒå¤´
        if not self.camera.start():
            print("âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
            return
        
        window_name = f"Screen Segmentation Collector - {self.width}x{self.height}"
        cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
        cv2.setMouseCallback(window_name, self.mouse_callback)
        
        try:
            while True:
                # è·å–å›¾åƒ (åªéœ€è¦å½©è‰²å›¾)
                rgb, _, _ = self.camera.get_frames()
                
                if rgb is not None:
                    self.current_color_image = rgb
                    display_image = self._draw_annotations(rgb)
                    cv2.imshow(window_name, display_image)
                
                # é”®ç›˜æ§åˆ¶
                key = cv2.waitKey(1) & 0xFF
                if key in (27, ord('q')):  # ESC or Q
                    break
                elif key == ord('a'):  # å¼€å§‹æ ‡æ³¨
                    if not self.is_annotating:
                        self.is_annotating = True
                        self.screen_corners = []
                        print("ğŸ“ å¼€å§‹æ ‡æ³¨æ¨¡å¼ - æŒ‰é¡ºåºç‚¹å‡»å±å¹•å››ä¸ªè§’ç‚¹")
                elif key == ord('s'):  # ä¿å­˜
                    if self.is_annotating and len(self.screen_corners) == 4:
                        self.save_sample()
                elif key == ord('r'):  # é‡ç½®
                    self.screen_corners = []
                    self.is_annotating = False
                    print("ğŸ”„ é‡ç½®æ ‡æ³¨")
                
        except KeyboardInterrupt:
            print("\nğŸ›‘ æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self.camera.stop()
            cv2.destroyAllWindows()
            print(f"\nğŸ“Š é‡‡é›†ç»Ÿè®¡: å…± {self.sample_count} ä¸ªæ ·æœ¬")
            print("ğŸ‘‹ æ•°æ®é‡‡é›†ç»“æŸ")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å±å¹•åˆ†å‰²æ•°æ®é‡‡é›†å™¨ (YOLOæ ¼å¼)")
    parser.add_argument("--output-dir", type=str, default="my_dataset/seg_960x540",
                       help="æ•°æ®é›†æ ¹ç›®å½•")
    parser.add_argument("--resolution", type=str, default="960x540",
                       choices=list(SUPPORTED_RESOLUTIONS.keys()),
                       help="é‡‡é›†åˆ†è¾¨ç‡")
    parser.add_argument("--width", type=int, help="è‡ªå®šä¹‰å®½åº¦")
    parser.add_argument("--height", type=int, help="è‡ªå®šä¹‰é«˜åº¦")
    
    args = parser.parse_args()
    
    # è§£æåˆ†è¾¨ç‡
    if args.width and args.height:
        width, height = args.width, args.height
    else:
        width, height = SUPPORTED_RESOLUTIONS[args.resolution]
    
    print(f"\nğŸ“Š æ•°æ®é‡‡é›†é…ç½®:")
    print(f"   åˆ†è¾¨ç‡: {width}x{height}")
    print(f"   è¾“å‡ºç›®å½•: {args.output_dir}")
    
    collector = ScreenSegmentationCollector(args.output_dir, width, height)
    collector.run()


if __name__ == "__main__":
    main()