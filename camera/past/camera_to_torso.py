import pyrealsense2 as rs
import numpy as np
import cv2
from scipy.spatial.transform import Rotation as R
import sys
import os

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'loco', 'unitree_sdk_python'))

from unitree_sdk2py.camera.realsense_camera_client import RealSenseCamera

class CoordTransfomer:
    def __init__(self):
        # URDF åŸå§‹å¹³ç§»å‚æ•°
        self.urdf_trans = np.array([0.0576235, 0.01753, 0.42987]) 
        
        # æ ¡å‡†å¥½çš„ Pitch
        self.pitch_offset = 0.23 
        self.base_pitch = 0.8307767239493009
        
        self._recalc_matrices()

    def _recalc_matrices(self):
        final_pitch = self.base_pitch + self.pitch_offset
        
        # Optical -> Link
        self.mat_opt_to_link = np.array([[0,0,1],[-1,0,0],[0,-1,0]])
        
        # Link -> Torso
        self.urdf_rpy = [0, final_pitch, 0]
        r_obj = R.from_euler('xyz', self.urdf_rpy, degrees=False)
        try: 
            self.mat_link_to_torso = r_obj.as_matrix()
        except: 
            self.mat_link_to_torso = r_obj.as_dcm()

    def process(self, point_cam_optical):
        P_opt = np.array(point_cam_optical)
        P_link = self.mat_opt_to_link @ P_opt
        P_torso = self.mat_link_to_torso @ P_link + self.urdf_trans
        return P_torso

class CameraApp:
    def __init__(self):
        # ä½¿ç”¨ RealSenseCamera å°è£…ç±»
        self.camera = RealSenseCamera(width=848, height=480, fps=30)
        self.transformer = CoordTransfomer()
        
        # åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„å˜é‡
        self.image_width = 848
        self.mouse_pos = (-1, -1)
        self.click_pos = None
        self.click_flag = False
        self.last_result = None

    def mouse_callback(self, event, x, y, flags, param):
        if event == cv2.EVENT_MOUSEMOVE:
            actual_x = x % self.image_width
            self.mouse_pos = (actual_x, y)
            
        elif event == cv2.EVENT_LBUTTONDOWN:
            actual_x = x % self.image_width
            self.mouse_pos = (actual_x, y)
            self.click_pos = (actual_x, y)
            self.click_flag = True

    def get_precise_depth(self, depth_image, x, y, max_search_radius=20):
        """
        ğŸŸ¢ æ”¹è¿›ç‰ˆ: å¹³é¢çº¦æŸä¸‹çš„æ™ºèƒ½æ·±åº¦æœç´¢
        
        ç­–ç•¥:
        1. ä¼˜å…ˆæ£€æŸ¥ä¸­å¿ƒç‚¹
        2. åŒå¿ƒåœ†æ‰©æ•£æœç´¢ (ä»ä¸­å¿ƒå‘å¤–)
        3. è¿”å›è·ç¦»æœ€è¿‘çš„æœ‰æ•ˆæ·±åº¦å€¼
        4. å¯è§†åŒ–æœç´¢åŠå¾„
        
        Args:
            depth_image: æ·±åº¦å›¾
            x, y: ç›®æ ‡åƒç´ åæ ‡
            max_search_radius: æœ€å¤§æœç´¢åŠå¾„ (åƒç´ )
        
        Returns:
            tuple: (depth_value, search_offset)
                - depth_value: æœ‰æ•ˆæ·±åº¦å€¼
                - search_offset: æœç´¢åç§»é‡ (x_offset, y_offset)
        """
        height, width = depth_image.shape
        
        # è¾¹ç•Œæ£€æŸ¥
        if not (0 <= x < width and 0 <= y < height):
            return 0, (0, 0)
        
        # ç­–ç•¥1: ç›´æ¥è¯»å–ä¸­å¿ƒåƒç´ 
        center_depth = depth_image[y, x]
        if center_depth > 0:
            return center_depth, (0, 0)
        
        # ç­–ç•¥2: åŒå¿ƒåœ†æ‰©æ•£æœç´¢
        for radius in range(1, max_search_radius + 1):
            # ç”Ÿæˆåœ†å‘¨ä¸Šçš„é‡‡æ ·ç‚¹
            candidates = []
            
            # ä½¿ç”¨Bresenhamåœ†ç®—æ³•ç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„ç‚¹
            num_samples = max(8, radius * 2)  # æ ¹æ®åŠå¾„è°ƒæ•´é‡‡æ ·å¯†åº¦
            for i in range(num_samples):
                angle = 2 * np.pi * i / num_samples
                dx = int(radius * np.cos(angle))
                dy = int(radius * np.sin(angle))
                
                nx, ny = x + dx, y + dy
                
                # è¾¹ç•Œæ£€æŸ¥
                if 0 <= nx < width and 0 <= ny < height:
                    depth_val = depth_image[ny, nx]
                    if depth_val > 0:
                        candidates.append((depth_val, dx, dy, radius))
            
            # æ‰¾åˆ°å½“å‰åŠå¾„ä¸Šçš„æœ‰æ•ˆæ·±åº¦
            if candidates:
                # ğŸŸ¢ ä¼˜å…ˆé€‰æ‹©æ·±åº¦å€¼æœ€æ¥è¿‘å¹³å‡å€¼çš„ç‚¹ (é¿å…å¼‚å¸¸å€¼)
                depths = [c[0] for c in candidates]
                median_depth = np.median(depths)
                
                # é€‰æ‹©æœ€æ¥è¿‘ä¸­å€¼çš„ç‚¹
                best_candidate = min(candidates, 
                                   key=lambda c: abs(c[0] - median_depth))
                
                depth_val, dx, dy, r = best_candidate
                print(f"  â†’ æœç´¢åŠå¾„ {r}px å¤„æ‰¾åˆ°æœ‰æ•ˆæ·±åº¦: {depth_val}")
                return depth_val, (dx, dy)
        
        # ç­–ç•¥3: å¦‚æœä»æœªæ‰¾åˆ°,ä½¿ç”¨åŒºåŸŸä¸­å€¼å¡«è¡¥
        print(f"  â†’ æœªæ‰¾åˆ°æœ‰æ•ˆæ·±åº¦,å°è¯•åŒºåŸŸå¡«è¡¥...")
        x_min = max(0, x - max_search_radius)
        x_max = min(width, x + max_search_radius + 1)
        y_min = max(0, y - max_search_radius)
        y_max = min(height, y + max_search_radius + 1)
        
        roi = depth_image[y_min:y_max, x_min:x_max]
        valid_pixels = roi[roi > 0]
        
        if len(valid_pixels) > 10:
            median_val = np.median(valid_pixels)
            print(f"  â†’ ä½¿ç”¨åŒºåŸŸä¸­å€¼: {median_val}")
            return median_val, (0, 0)
        
        return 0, (0, 0)

    def run(self):
        print("[INFO] æ­£åœ¨å¯åŠ¨ç›¸æœº...")
        
        if not self.camera.start():
            print("âŒ ç›¸æœºå¯åŠ¨å¤±è´¥")
            return
        
        intrinsics = self.camera.depth_intrinsics
        depth_scale = self.camera.depth_scale

        cv2.namedWindow("RealSense High Precision")
        cv2.setMouseCallback("RealSense High Precision", self.mouse_callback)

        print("\n=== ç³»ç»Ÿå°±ç»ª (å¹³é¢æ·±åº¦æœç´¢æ¨¡å¼) ===")
        print("ğŸ“Œ å·¦ä¾§: å½©è‰²å›¾ | å³ä¾§: æ·±åº¦å›¾")
        print("ğŸ” è‡ªåŠ¨æœç´¢æœ€è¿‘æœ‰æ•ˆæ·±åº¦ (æœ€å¤§åŠå¾„20px)")
        print("âŒ¨ï¸  æŒ‰ 'Q' é€€å‡º | æŒ‰ 'S' ä¿å­˜ | æŒ‰ 'C' æ¸…é™¤")

        try:
            while True:
                color_image, depth_raw, depth_colored = self.camera.get_frames()
                
                if color_image is None or depth_raw is None:
                    continue

                display_color = color_image.copy()
                display_depth = depth_colored.copy()

                # å¤„ç†ç‚¹å‡»äº‹ä»¶
                if self.click_flag:
                    self.click_flag = False
                    u, v = self.click_pos
                    
                    # ğŸŸ¢ ä½¿ç”¨æ”¹è¿›çš„æ·±åº¦æœç´¢
                    depth_value, search_offset = self.get_precise_depth(
                        depth_raw, u, v, max_search_radius=20
                    )
                    dist = depth_value * depth_scale
                    
                    if dist > 0:
                        # è®¡ç®—å®é™…ä½¿ç”¨çš„åƒç´ åæ ‡
                        actual_u = u + search_offset[0]
                        actual_v = v + search_offset[1]
                        
                        # åæŠ•å½±åˆ°ç›¸æœºåæ ‡ç³»
                        pt_opt = rs.rs2_deproject_pixel_to_point(
                            intrinsics, [actual_u, actual_v], dist
                        )
                        pt_torso = self.transformer.process(pt_opt)

                        self.last_result = {
                            'pixel': (u, v),
                            'actual_pixel': (actual_u, actual_v),
                            'depth': dist,
                            'torso': pt_torso,
                            'search_offset': search_offset
                        }

                        print(f"\nğŸ“ ç‚¹å‡»: ({u}, {v})")
                        if search_offset != (0, 0):
                            print(f"ğŸ” å®é™…: ({actual_u}, {actual_v}) [åç§» {search_offset}]")
                        print(f"ğŸ“ æ·±åº¦: {dist:.3f}m")
                        print(f"ğŸ¤– Torso: X={pt_torso[0]:.3f}, Y={pt_torso[1]:.3f}, Z={pt_torso[2]:.3f}")
                    else:
                        print(f"\nâŒ åƒç´ : ({u}, {v}) - æœç´¢åŠå¾„20pxå†…æ— æœ‰æ•ˆæ·±åº¦")
                        self.last_result = None

                # ğŸŸ¢ ç»˜åˆ¶å¢å¼ºç‰ˆæ ‡è®°
                if self.last_result:
                    u, v = self.last_result['pixel']
                    actual_u, actual_v = self.last_result['actual_pixel']
                    pt_torso = self.last_result['torso']
                    dist = self.last_result['depth']
                    offset = self.last_result['search_offset']
                    
                    label = f"Z:{pt_torso[2]:.2f}m D:{dist:.2f}m"
                    
                    # åœ¨å½©è‰²å›¾ä¸Šç»˜åˆ¶
                    # ç‚¹å‡»ä½ç½® (é»„è‰²å‰)
                    cv2.drawMarker(display_color, (u, v), (0, 255, 255), 
                                  cv2.MARKER_TILTED_CROSS, 15, 2)
                    
                    # å®é™…é‡‡æ ·ä½ç½® (çº¢è‰²åœ†)
                    if offset != (0, 0):
                        cv2.circle(display_color, (actual_u, actual_v), 5, (0, 0, 255), -1)
                        cv2.circle(display_color, (actual_u, actual_v), 8, (0, 255, 255), 1)
                        # è¿æ¥çº¿
                        cv2.line(display_color, (u, v), (actual_u, actual_v), 
                                (255, 255, 0), 1)
                    else:
                        cv2.circle(display_color, (u, v), 5, (0, 255, 0), -1)
                    
                    cv2.putText(display_color, label, (actual_u+12, actual_v-5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                    
                    # åœ¨æ·±åº¦å›¾ä¸ŠåŒæ ·ç»˜åˆ¶
                    cv2.drawMarker(display_depth, (u, v), (0, 255, 255), 
                                  cv2.MARKER_TILTED_CROSS, 15, 2)
                    if offset != (0, 0):
                        cv2.circle(display_depth, (actual_u, actual_v), 5, (0, 0, 255), -1)
                        cv2.line(display_depth, (u, v), (actual_u, actual_v), 
                                (255, 255, 0), 1)
                    else:
                        cv2.circle(display_depth, (u, v), 5, (0, 255, 0), -1)
                    
                    cv2.putText(display_depth, label, (actual_u+12, actual_v-5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                # é¼ æ ‡æ‚¬åœæ ‡è®°
                if self.mouse_pos[0] >= 0:
                    mx, my = self.mouse_pos
                    cv2.drawMarker(display_color, (mx, my), (0, 255, 255), 
                                  cv2.MARKER_CROSS, 12, 1)
                    cv2.drawMarker(display_depth, (mx, my), (0, 255, 255), 
                                  cv2.MARKER_CROSS, 12, 1)
                
                # å¹¶æ’æ˜¾ç¤º
                display_image = cv2.hconcat([display_color, display_depth])
                h = display_image.shape[0]
                cv2.line(display_image, (self.image_width, 0), 
                        (self.image_width, h), (255, 255, 255), 2)
                
                cv2.imshow("RealSense High Precision", display_image)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    self.camera.save_images("data/images", prefix="torso")
                    print("ğŸ’¾ å›¾åƒå·²ä¿å­˜")
                elif key == ord('c'):
                    self.last_result = None
                    print("ğŸ§¹ æ ‡è®°å·²æ¸…é™¤")

        except KeyboardInterrupt:
            print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.camera.stop()
            cv2.destroyAllWindows()
            print("[INFO] ç¨‹åºå·²é€€å‡º")

if __name__ == "__main__":
    CameraApp().run()