#!/usr/bin/env python3
"""
integrated_emergency_demo.py
============================
é›†æˆæ¼”ç¤ºï¼š
1. è¯­éŸ³äº¤äº’ (å¼‚å¸¸æ’­æŠ¥ -> ç¡®è®¤)
2. ç§»åŠ¨æ§åˆ¶ (åé€€ -> å³è½¬ -> å‰è¿› -> å·¦è½¬ -> å‰è¿›)
3. åŠ¨ä½œæ‰§è¡Œ (æ‰‹æœºè§¦æ‘¸ï¼Œä½¿ç”¨äººå·¥æ•°æ®)
"""

import sys
import os
import time
import math
import socket
import tempfile
import numpy as np
import requests
import json
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../audio')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../motion_control')))

# å¯¼å…¥ä¾èµ–
from unitree_sdk2py.core.channel import ChannelFactoryInitialize
from unitree_sdk2py.g1.loco.g1_loco_client import LocoClient
from unitree_sdk2py.dds.odometry_client import OdometryClient

# å°è¯•å¯¼å…¥éŸ³é¢‘æ¨¡å—
try:
    from audio_record import AudioRecorder, CHANNELS, SAMPLE_WIDTH, FRAME_RATE
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ audio_recordï¼Œè¯·æ£€æŸ¥è·¯å¾„")
    sys.exit(1)

# å¯¼å…¥åŠ¨ä½œæ‰§è¡Œæ¨¡å—
try:
    from phone_touch_task import PhoneTouchController, RobotControlError, SafetyLimitError
    from common.robot_state_manager import robot_state
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ phone_touch_task æˆ– robot_state")
    sys.exit(1)

# ==================== é…ç½® ====================
TTS_SERVER_URL = "http://192.168.77.103:28001/speak_msg"
TTS_MONITOR_URL = "http://192.168.77.103:28001/monitor"
ASR_SERVER_URL = "http://localhost:8003/asr"

# äººå·¥é‡‡é›†çš„IKæ•°æ® (éœ€è¦ç”¨æˆ·æ›¿æ¢ä¸ºçœŸå®æ•°æ®)
# æ ¼å¼: (joint_angles_list, torso_coord_tuple)
# joint_angles: [shoulder_pitch, shoulder_roll, shoulder_yaw, elbow, wrist_roll, wrist_pitch, wrist_yaw]
# torso_coord: (x, y, z)
MANUAL_IK_DATA = (
    [-0.576536, 0.256975, -0.006111, 0.711639, 1.315164, -0.042154, 0.251519],  # ç¤ºä¾‹å…³èŠ‚è§’åº¦
    (0.337,0.267,-0.178)                       # ç¤ºä¾‹ç›®æ ‡åæ ‡
)

# ==================== è¯­éŸ³æ¨¡å— ====================
class TTSClient:
    """HTTP TTS å®¢æˆ·ç«¯"""
    @staticmethod
    def speak(text, volume=100, wait=True):
        if not text: return
        try:
            payload = {"speak_msg": text, "volume": volume, "source": "integrated"}
            headers = {"Content-Type": "application/json"}
            print(f"ğŸ”Š {text}")
            response = requests.post(TTS_SERVER_URL, json=payload, headers=headers, timeout=2.0)
            if response.status_code != 200:
                print(f"âš ï¸ TTSé”™è¯¯: {response.status_code}")
                return
            
            if wait:
                result = response.json()
                data = result.get('data')
                if data and isinstance(data, dict):
                    task_id = data.get('task_id')
                    if task_id:
                        TTSClient._wait_for_completion(task_id)
        except Exception as e:
            print(f"âŒ TTSå¤±è´¥: {e}")

    @staticmethod
    def _wait_for_completion(task_id, timeout=30):
        start_time = time.time()
        while time.time() - start_time < timeout:
            try:
                response = requests.get(TTS_MONITOR_URL, timeout=2.0)
                if response.status_code == 200:
                    data = response.json()
                    active_task = data.get('active_task')
                    queue_length = data.get('queue_length', 0)
                    if not active_task and queue_length == 0:
                        time.sleep(0.5) 
                        return True
            except:
                pass
            time.sleep(0.1)
        return False

class ASRClient:
    """HTTP ASR å®¢æˆ·ç«¯"""
    @staticmethod
    def recognize(audio_data):
        if audio_data is None or len(audio_data) == 0: return ""
        try:
            import wave
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_path = tmp_file.name
                with wave.open(tmp_path, 'wb') as wav_file:
                    wav_file.setnchannels(CHANNELS)
                    wav_file.setsampwidth(SAMPLE_WIDTH)
                    wav_file.setframerate(FRAME_RATE)
                    wav_file.writeframes(audio_data.tobytes())
            
            with open(tmp_path, 'rb') as f:
                files = {'file': (f'audio.wav', f, 'audio/wav')}
                response = requests.post(ASR_SERVER_URL, files=files, timeout=10.0)
            os.remove(tmp_path)
            
            if response.status_code == 200:
                return response.json().get('text', '').strip()
            return ""
        except Exception as e:
            print(f"âŒ ASRå¤±è´¥: {e}")
            return ""

class VoiceInteraction(AudioRecorder):
    def __init__(self, interface_name="eth0"):
        super().__init__(interface_name)
        self.setup_audio_receiver()
        
    def listen_for_seconds(self, duration=6.0):
        print(f"\nğŸ‘‚ å¼€å§‹ç›‘å¬ ({duration}ç§’)...")
        buffer = []
        start_time = time.time()
        while time.time() - start_time < duration:
            try:
                data, _ = self.socket.recvfrom(2048)
                audio_np = np.frombuffer(data, dtype=np.int16)
                buffer.extend(audio_np)
            except socket.timeout:
                continue
            except Exception:
                break
        print("â¹ï¸ ç›‘å¬ç»“æŸ")
        return np.array(buffer)

    def run(self):
        try:
            # 1. æ’­æŠ¥å¼‚å¸¸
            TTSClient.speak("è´¢åº™å˜è´¢åº™å˜/110kV.å€šè´¢çº¿å¹ºæ ‹å¹ºå¼€å…³è·³é—¸ï¼ˆé‡åˆæˆåŠŸï¼‰(æ¨¡æ‹Ÿ)", wait=False)
            
            # 2. è¯¢é—®
            TTSClient.speak("æ˜¯å¦éœ€è¦æ‹¨æ‰“å¯¹åº”å˜ç”µç«™ç”µè¯", wait=False)
            
            # # 3. ç›‘å¬
            # audio_data = self.listen_for_seconds(3.0)
            # if len(audio_data) == 0:
            #     print("âš ï¸ æœªé‡‡é›†åˆ°éŸ³é¢‘æ•°æ®")
            #     TTSClient.speak("æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ“ä½œå–æ¶ˆ", wait=True)
            #     return False

            # # 4. è¯†åˆ«
            # print("ğŸ¤” æ­£åœ¨è¯†åˆ«...")
            # text = ASRClient.recognize(audio_data)
            # print(f"ğŸ“ è¯†åˆ«ç»“æœ: [{text}]")
            
            # keywords = ["éœ€è¦", "æ˜¯", "æ‹¨æ‰“", "ç¡®è®¤", "å¥½çš„","è¦","éœ€","é¡»","è¯"]
            # confirmed = any(k in text for k in keywords)
            
            # æ’å…¥åŠ¨ä½œåºåˆ—
            print("\nğŸ’ª æ‰§è¡Œç¡®è®¤åŠ¨ä½œåºåˆ—...")
            try:
                # åŠ¨æ€å¯¼å…¥ FullBodyPoseSequence
                sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../arm2dex3_control')))
                from exec_dual_arm2dex3_sequence import FullBodyPoseSequence
                
                action_controller = FullBodyPoseSequence(interface=self.interface_name)
                if action_controller.initialize():
                    SEQUENCE = [
                        ("nature", "nature", "nature", "nature"), 
                        ("inte_up", "keep", "open_1", "nature"),
                        ("nature", "inte_up", "close", "hello"),
                        ("nature", "nature", "nature", "nature")
                    ]
                    action_controller.run_sequence(SEQUENCE, speed_factor=1.0, pause_time=1.0)
                else:
                    print("âš ï¸ åŠ¨ä½œæ§åˆ¶å™¨åˆå§‹åŒ–å¤±è´¥")
            except Exception as e:
                print(f"âš ï¸ åŠ¨ä½œæ‰§è¡Œå‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
            finally:
                # åŠ¡å¿…å…³é—­æ§åˆ¶å™¨ä»¥é‡Šæ”¾èµ„æºï¼Œç¡®ä¿æ‰‹è‡‚åœæ­¢æ§åˆ¶
                if 'action_controller' in locals():
                    action_controller.shutdown()
                    print("âœ… åŠ¨ä½œæ§åˆ¶å™¨å·²å…³é—­ (æ‰‹è‡‚æ§åˆ¶å·²é‡Šæ”¾)")

            # confirmed = False
            # time.sleep(10)
            # ç­‰å¾…ç”¨æˆ·è¾“å…¥ç¡®è®¤
            user_input = input("è¯·è¾“å…¥ 'y' ç¡®è®¤æ‰§è¡Œä¸‹ä¸€æ­¥ (è¾“å…¥å…¶ä»–å–æ¶ˆ): ").strip().lower()
            confirmed = (user_input == 'y')
            if confirmed:
                print("âœ… ç”¨æˆ·ç¡®è®¤")
                TTSClient.speak("æ”¶åˆ°", wait=True)
                return True
            else:
                print("âŒ ç”¨æˆ·å–æ¶ˆ")
                TTSClient.speak("æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ“ä½œå–æ¶ˆ", wait=True)
                return False
        finally:
            self.socket.close()

# ==================== ç§»åŠ¨æ¨¡å— ====================
class LocomotionController:
    def __init__(self, interface="eth0"):
        self.interface = interface
        self.LINEAR_VELOCITY = 0.3
        self.ANGULAR_VELOCITY = 0.50
        self.POSITION_TOLERANCE = 0.05
        self.ANGLE_TOLERANCE = 0.08
        self.loco_client = None
        self.odom_client = None

    def initialize(self):
        try:
            print("ğŸ“¡ åˆå§‹åŒ–é‡Œç¨‹è®¡...")
            self.odom_client = OdometryClient(interface=self.interface, use_high_freq=False, use_low_freq=True)
            if not self.odom_client.initialize():
                print("âŒ é‡Œç¨‹è®¡åˆå§‹åŒ–å¤±è´¥")
                return False
            time.sleep(0.5)
            
            self.loco_client = LocoClient()
            self.loco_client.Init()
            print("âœ… ç§»åŠ¨æ§åˆ¶åˆå§‹åŒ–å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ ç§»åŠ¨æ§åˆ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def move_distance(self, distance: float):
        direction = 1 if distance > 0 else -1
        target_distance = abs(distance)
        start_pos = self.odom_client.get_current_position()
        start_x, start_y = start_pos[0], start_pos[1]
        
        print(f"{'ğŸš¶ å‰è¿›' if direction > 0 else 'ğŸš¶ åé€€'} {target_distance:.2f}m")
        base_velocity = self.LINEAR_VELOCITY * direction
        max_time = target_distance / abs(self.LINEAR_VELOCITY) + 10
        start_time = time.time()
        
        try:
            while time.time() - start_time < max_time:
                curr_pos = self.odom_client.get_current_position()
                curr_x, curr_y = curr_pos[0], curr_pos[1]
                moved = math.sqrt((curr_x - start_x)**2 + (curr_y - start_y)**2)
                remaining = target_distance - moved
                
                if remaining <= self.POSITION_TOLERANCE: break
                
                velocity = base_velocity * max(0.3, remaining / 0.2) if remaining < 0.2 else base_velocity
                self.loco_client.Move(vx=velocity, vy=0.0, vyaw=0.0, continous_move=True)
                time.sleep(0.05)
            self.loco_client.StopMove()
            time.sleep(0.3)
        except Exception as e:
            print(f"âŒ ç§»åŠ¨å¼‚å¸¸: {e}")
            self.loco_client.StopMove()

    def turn_90(self, is_left: bool, angle_deg: float = 90):
        """è½¬å‘æŒ‡å®šè§’åº¦ (ä½¿ç”¨ç»å¯¹è§’åº¦å·®æ§åˆ¶)"""
        target_angle = math.radians(angle_deg)
        print(f"ğŸ”„ {'å·¦' if is_left else 'å³'}è½¬ {angle_deg}Â°")
        
        start_yaw = self.odom_client.get_current_yaw()
        target_yaw_diff = target_angle if is_left else -target_angle
        
        omega = self.ANGULAR_VELOCITY
        max_time = target_angle / self.ANGULAR_VELOCITY + 10
        start_time = time.time()
        
        try:
            while time.time() - start_time < max_time:
                curr_yaw = self.odom_client.get_current_yaw()
                
                # è®¡ç®—å½“å‰ç›¸å¯¹äºèµ·å§‹ç‚¹çš„è§’åº¦å˜åŒ– (å½’ä¸€åŒ–å¤„ç†)
                current_diff = curr_yaw - start_yaw
                current_diff = math.atan2(math.sin(current_diff), math.cos(current_diff))
                
                # è®¡ç®—å‰©ä½™éœ€è¦è½¬è¿‡çš„è§’åº¦
                remaining = target_yaw_diff - current_diff
                remaining = math.atan2(math.sin(remaining), math.cos(remaining))
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®æ ‡ (å…è®¸è¯¯å·®)
                if abs(remaining) <= self.ANGLE_TOLERANCE:
                    break
                
                # è‡ªé€‚åº”è§’é€Ÿåº¦ï¼ˆæ¥è¿‘ç›®æ ‡æ—¶å‡é€Ÿï¼‰
                rot_direction = 1.0 if remaining > 0 else -1.0
                
                if abs(remaining) < math.radians(30):
                    scale = max(0.6, abs(remaining) / math.radians(30))
                    current_omega = omega * scale * rot_direction
                else:
                    current_omega = omega * rot_direction
                
                self.loco_client.Move(vx=0.0, vy=0.0, vyaw=current_omega, continous_move=True)
                time.sleep(0.05)
            
            self.loco_client.StopMove()
            time.sleep(0.8)
            
            # ç»“æœéªŒè¯
            final_yaw = self.odom_client.get_current_yaw()
            final_delta = final_yaw - start_yaw
            final_delta = math.atan2(math.sin(final_delta), math.cos(final_delta))
            error_deg = math.degrees(abs(target_yaw_diff - final_delta))
            print(f"âœ… è½¬å‘å®Œæˆ: å®é™…è½¬è¿‡ {math.degrees(final_delta):.1f}Â°, è¯¯å·® {error_deg:.1f}Â°")

            
        except Exception as e:
            print(f"âŒ æ—‹è½¬å¼‚å¸¸: {e}")
            self.loco_client.StopMove()

    def run_sequence(self):
        print("\nğŸš€ å¼€å§‹ç§»åŠ¨åºåˆ—")
        # 1. å‘åç§»åŠ¨ 0.9m
        # self.move_distance(-0.9)
        # 2. å‘å³è½¬ 85åº¦
        self.turn_90(is_left=False, angle_deg=85)
        # 3. å‰è¿› 3m
        self.move_distance(2.2)
        # 4. å‘å·¦è½¬ 90åº¦
        self.turn_90(is_left=True, angle_deg=90)
        # 5. å‰è¿› 0.6m
        self.move_distance(0.8)
        
        TTSClient.speak("é©¬ä¸Šä¸ºæ‚¨æ‹¨é€šï¼Œè¯·ç¨å€™", wait=False)

        print("âœ¨ ç§»åŠ¨åºåˆ—å®Œæˆ")

# ==================== åŠ¨ä½œæ¨¡å— ====================
class ManualActionController(PhoneTouchController):
    def execute_with_manual_data(self, manual_data):
        print("\n" + "="*70)
        print("ğŸ¯ å¼€å§‹æ‰§è¡Œäººå·¥æ•°æ®åŠ¨ä½œä»»åŠ¡")
        print("="*70)
        
        try:
            self.target_joint_angles, self.target_torso_coord = manual_data
            
            print(f"ğŸ“ ç›®æ ‡ Torso åæ ‡: {self.target_torso_coord}")
            print(f"ğŸ”§ ç›®æ ‡å…³èŠ‚è§’åº¦: {self.target_joint_angles}")

            with robot_state.safe_arm_control(arm="left", source="integrated_demo", timeout=180.0):
                # æ­¥éª¤1: é¢„å¤‡å§¿æ€
                print(f"\nã€æ­¥éª¤1ã€‘æ‰§è¡Œé¢„å¤‡å§¿æ€åºåˆ—")
                prepare_sequence = ["phone_pre_1", "phone_pre_2", "phone_pre_3", "phone_pre_final"]
                for pose in prepare_sequence:
                    if not self.move_arm_to_pose(pose): raise RobotControlError(f"ç§»åŠ¨åˆ°é¢„å¤‡å§¿æ€å¤±è´¥: {pose}")
                
                # æ­¥éª¤2: çµå·§æ‰‹
                print(f"\nã€æ­¥éª¤2ã€‘è®¾ç½®çµå·§æ‰‹å§¿æ€")
                if not self.move_hand_to_pose("phone_pre_1"): raise RobotControlError("ç§»åŠ¨çµå·§æ‰‹å¤±è´¥")

                # æ­¥éª¤3: ç§»åŠ¨åˆ°ç›®æ ‡
                print(f"\nã€æ­¥éª¤3ã€‘ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®")
                if not self.move_arm_to_angles(self.target_joint_angles): raise RobotControlError("ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®å¤±è´¥")
                
                # æ­¥éª¤4: åŠ¨ä½œ (æ‘†åŠ¨)
                print(f"\nã€æ­¥éª¤4ã€‘æ‰§è¡ŒåŠ¨ä½œ(æ‘†åŠ¨)")
                WRIST_YAW_INDEX = 6
                self.adjust_single_joint(WRIST_YAW_INDEX, self.wrist_pitch)
                self.adjust_single_joint(WRIST_YAW_INDEX, -self.wrist_pitch)
                
                # æ­¥éª¤5: è®¾ç½®çµå·§æ‰‹æ¢å¤åŸä½
                print(f"\nã€æ­¥éª¤5ã€‘è®¾ç½®çµå·§æ‰‹æ¢å¤åŸä½")
                if not self.move_hand_to_pose("close"):
                    raise RobotControlError("çµå·§æ‰‹å¤ä½å¤±è´¥")

                # æ­¥éª¤6: è‚˜å…³èŠ‚æ”¶ç¼©
                print(f"\nã€æ­¥éª¤6ã€‘è‚˜å…³èŠ‚æ”¶ç¼©")
                ELBOW_INDEX = 3
                print("  ğŸ’ª æ”¶ç¼© -0.5 rad")
                self.adjust_single_joint(ELBOW_INDEX, -0.5)

                # æ’­æŠ¥å®Œæˆä¿¡æ¯
                TTSClient.speak("è´¢åº™å˜è´¢åº™å˜/110kV.å€šè´¢çº¿å¹ºæ ‹å¹ºå¼€å…³è·³é—¸ï¼ˆé‡åˆæˆåŠŸï¼‰(æ¨¡æ‹Ÿ)", wait=False)
                
                # æ­¥éª¤7: æ’¤é€€
                print(f"\nã€æ­¥éª¤7ã€‘æ’¤é€€")
                retreat_sequence = ["phone_pre_final", "phone_pre_3", "phone_pre_2", "phone_pre_1"]
                for pose in retreat_sequence:
                    self.move_arm_to_pose(pose)
                    
            print("âœ¨ åŠ¨ä½œä»»åŠ¡å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åŠ¨ä½œæ‰§è¡Œå¤±è´¥: {e}")
            if self.arm_client:
                self.move_arm_to_pose("phone_pre_1")

# ==================== ä¸»å…¥å£ ====================
def main():
    if len(sys.argv) < 2:
        interface = "eth0"
    else:
        interface = sys.argv[1]
        
    print("ğŸš€ å¯åŠ¨é›†æˆæ¼”ç¤ºç¨‹åº")
    ChannelFactoryInitialize(0, interface)
    
    # 1. è¯­éŸ³äº¤äº’
    voice = VoiceInteraction(interface)
    if not voice.run():
        return
        
    # 2. ç§»åŠ¨
    mover = LocomotionController(interface)
    if not mover.initialize():
        return
    mover.run_sequence()
    
    # 3. åŠ¨ä½œ
    # é»˜è®¤ä½¿ç”¨å¸¸è§„è¿æ§æ¨¡å¼å‚æ•°ï¼Œå¦‚éœ€ä¿®æ”¹è¯·åœ¨æ­¤è°ƒæ•´
    action = ManualActionController(
        interface=interface,
        expected_torso_z=-0.15,
        wrist_pitch=-0.60
    )
    if not action.initialize():
        return
        
    try:
        action.execute_with_manual_data(MANUAL_IK_DATA)
    finally:
        action.shutdown()

if __name__ == "__main__":
    main()